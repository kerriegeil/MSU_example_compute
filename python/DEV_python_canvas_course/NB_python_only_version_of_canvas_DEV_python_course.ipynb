{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Many Ways to Use Dask for Parallel Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "Dask is a python package that enables parallel processing on your personal computer and parallel or distributed processing on a high-performance computing system (HPC). With Dask, you can take advantage of all the threads on your laptop or desktop to speed up your computations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Comparing compute time for:\n",
    "\n",
    "compute type | data structure | packages\n",
    "---|---|---\n",
    "fortran-style looping | numpy array | numpy \n",
    "fortran-style looping sped up with numba | numpy array | numpy+numba \n",
    "vectorized computation | numpy array | numpy \n",
    "vectorized parallelized computation | dask array | numpy, dask, dask.distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) build the conda environment in the repo (daskdemo.yml) before running this notebook\n",
    "\n",
    "    assuming you've already installed conda:\n",
    "\n",
    "    ```\n",
    "    conda env create -f daskdemo.yml\n",
    "    ```\n",
    "\n",
    "    if the yml doesn't work or takes forever\n",
    "    ```\n",
    "    conda create --name daskdemo -c conda-forge dask distributed netcdf4 numpy matplotlib xarray jupyter\n",
    "    ```\n",
    "\n",
    "\n",
    "2) once you've created the environment\n",
    "    ```\n",
    "    conda activate daskdemo\n",
    "    python -m ipykernel install --user --name daskdemo\n",
    "    ```\n",
    "\n",
    "3) import to your IDE and select the environment as your kernel\n",
    "\n",
    "    e.g. for VScode IDE: View > Command Palette > Python: Select Interpreter > choose daskdemo, then select daskdemo as the kernel in the upper right of the notebook\n",
    "\n",
    "    for other IDE's, Google how to access a conda environment\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "# from dask.distributed import Client\n",
    "\n",
    "from time import time as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# xr just for creating dummy data \n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the spatial resolution of the data\n",
    "# e.g. grids_per_degree=4 means 4 grid boxes per degree lat or lon (1/4 degree x 1/4 degree gridsize, 16 grids in a 1x1 degree area)\n",
    "# enter dtype int here\n",
    "grids_per_degree=8\n",
    "\n",
    "# define number of chunks\n",
    "# e.g. chunk_scale**2 total chunks, chunk_scale of 4 yield 16 chunks\n",
    "# enter dtype int here, preferably in a multiple of the number of cores in your processor\n",
    "chunk_scale=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid and array \n",
    "gx=360\n",
    "gy=180\n",
    "nx=gx*grids_per_degree\n",
    "ny=gy*grids_per_degree\n",
    "nt=365\n",
    "\n",
    "lat=np.linspace(-90,90,ny+1).astype('float32') # location of grid box edges\n",
    "lat=(lat+abs((lat[-1]-lat[-2])/2))[:-1] # grid centers\n",
    "lon=np.linspace(-180,180,nx,endpoint=False).astype('float32') # grid edges\n",
    "lon=(lon+abs((lon[-1]-lon[-2])/2)) # grid centers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;tmax&#x27; (doy: 365)&gt;\n",
       "[365 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * doy      (doy) int32 1 2 3 4 5 6 7 8 9 ... 358 359 360 361 362 363 364 365\n",
       "Attributes:\n",
       "    standard_name:  maximum_temperature\n",
       "    long_name:      2m Maximum Temperature\n",
       "    units:          C\n",
       "    description:    maximum air temperature at 2m above surface\n",
       "    grid_mapping:   spatial_ref</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'tmax'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>doy</span>: 365</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-2478d882-06e7-4188-852f-aa12991b29dc' class='xr-array-in' type='checkbox' checked><label for='section-2478d882-06e7-4188-852f-aa12991b29dc' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>...</span></div><div class='xr-array-data'><pre>[365 values with dtype=float32]</pre></div></div></li><li class='xr-section-item'><input id='section-c3ba4e5e-ae77-4faf-a0de-93f9195bcef1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c3ba4e5e-ae77-4faf-a0de-93f9195bcef1' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>doy</span></div><div class='xr-var-dims'>(doy)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>1 2 3 4 5 6 ... 361 362 363 364 365</div><input id='attrs-9f473850-6577-44ea-969c-62d68d529c5d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9f473850-6577-44ea-969c-62d68d529c5d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-24512a41-eb6d-464f-811c-cb15f4cc6415' class='xr-var-data-in' type='checkbox'><label for='data-24512a41-eb6d-464f-811c-cb15f4cc6415' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>doy</dd><dt><span>long_name :</span></dt><dd>day of year</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([  1,   2,   3, ..., 363, 364, 365])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-92cf2ed4-67b9-4934-897b-77860db6304c' class='xr-section-summary-in' type='checkbox'  ><label for='section-92cf2ed4-67b9-4934-897b-77860db6304c' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>doy</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-cb637f26-c2d2-4625-9340-37c909072eda' class='xr-index-data-in' type='checkbox'/><label for='index-cb637f26-c2d2-4625-9340-37c909072eda' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "       ...\n",
       "       356, 357, 358, 359, 360, 361, 362, 363, 364, 365],\n",
       "      dtype=&#x27;int32&#x27;, name=&#x27;doy&#x27;, length=365))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-11a76dae-3eb5-4e8f-8661-0588eceb1ee5' class='xr-section-summary-in' type='checkbox'  checked><label for='section-11a76dae-3eb5-4e8f-8661-0588eceb1ee5' class='xr-section-summary' >Attributes: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>maximum_temperature</dd><dt><span>long_name :</span></dt><dd>2m Maximum Temperature</dd><dt><span>units :</span></dt><dd>C</dd><dt><span>description :</span></dt><dd>maximum air temperature at 2m above surface</dd><dt><span>grid_mapping :</span></dt><dd>spatial_ref</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'tmax' (doy: 365)>\n",
       "[365 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * doy      (doy) int32 1 2 3 4 5 6 7 8 9 ... 358 359 360 361 362 363 364 365\n",
       "Attributes:\n",
       "    standard_name:  maximum_temperature\n",
       "    long_name:      2m Maximum Temperature\n",
       "    units:          C\n",
       "    description:    maximum air temperature at 2m above surface\n",
       "    grid_mapping:   spatial_ref"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull a single temperature timeseries from some local data files\n",
    "# read data in as xarray dataArrays\n",
    "tmax = xr.open_dataset(data_dir+'tmax_daily_singlegrid_8110.nc')['tmax'].squeeze().reset_coords(['lat','lon'],drop=True)\n",
    "tmin = xr.open_dataset(data_dir+'tmin_daily_singlegrid_8110.nc')['tmin'].squeeze().reset_coords(['lat','lon'],drop=True)\n",
    "tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m newshape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tmin),\u001b[38;5;28mlen\u001b[39m(lat),\u001b[38;5;28mlen\u001b[39m(lon))\n\u001b[1;32m----> 2\u001b[0m test\u001b[38;5;241m=\u001b[39mda\u001b[38;5;241m.\u001b[39mbroadcast_to(\u001b[43mtmin\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m,newshape,chunks\u001b[38;5;241m=\u001b[39m(nt,\u001b[38;5;28mint\u001b[39m(nx\u001b[38;5;241m/\u001b[39mchunk_scale),\u001b[38;5;28mint\u001b[39m(ny\u001b[38;5;241m/\u001b[39mchunk_scale)))\n\u001b[0;32m      3\u001b[0m test\n",
      "File \u001b[1;32mc:\\Users\\kerrie\\.conda\\envs\\daskdemo\\lib\\site-packages\\xarray\\core\\dataarray.py:847\u001b[0m, in \u001b[0;36mDataArray.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_coord(key)\n\u001b[0;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     \u001b[39m# xarray-style array indexing\u001b[39;00m\n\u001b[1;32m--> 847\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misel(indexers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_item_key_to_dict(key))\n",
      "File \u001b[1;32mc:\\Users\\kerrie\\.conda\\envs\\daskdemo\\lib\\site-packages\\xarray\\core\\dataarray.py:828\u001b[0m, in \u001b[0;36mDataArray._item_key_to_dict\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39mif\u001b[39;00m utils\u001b[39m.\u001b[39mis_dict_like(key):\n\u001b[0;32m    827\u001b[0m     \u001b[39mreturn\u001b[39;00m key\n\u001b[1;32m--> 828\u001b[0m key \u001b[39m=\u001b[39m indexing\u001b[39m.\u001b[39;49mexpanded_indexer(key, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mndim)\n\u001b[0;32m    829\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims, key))\n",
      "File \u001b[1;32mc:\\Users\\kerrie\\.conda\\envs\\daskdemo\\lib\\site-packages\\xarray\\core\\indexing.py:232\u001b[0m, in \u001b[0;36mexpanded_indexer\u001b[1;34m(key, ndim)\u001b[0m\n\u001b[0;32m    230\u001b[0m         new_key\u001b[39m.\u001b[39mappend(k)\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_key) \u001b[39m>\u001b[39m ndim:\n\u001b[1;32m--> 232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtoo many indices\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    233\u001b[0m new_key\u001b[39m.\u001b[39mextend((ndim \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(new_key)) \u001b[39m*\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)])\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(new_key)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices"
     ]
    }
   ],
   "source": [
    "newshape=(len(tmin),len(lat),len(lon))\n",
    "test=da.broadcast_to(tmin[:,np.newaxis,np.newaxis],newshape,chunks=(nt,int(nx/chunk_scale),int(ny/chunk_scale)))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dummy data\n",
    "def meanT_global_daily_dummy_data(nx,ny,nt,grids_per_degree,chunk_scale,tmax_xr,tmin_xr):\n",
    "    # create lat lon grid centers based on the nx and ny dimensions\n",
    "    lat=np.linspace(-90,90,ny+1).astype('float32') # location of grid box edges\n",
    "    lat=(lat+abs((lat[-1]-lat[-2])/2))[:-1] # grid centers\n",
    "    lon=np.linspace(-180,180,nx,endpoint=False).astype('float32') # grid edges\n",
    "    lon=(lon+abs((lon[-1]-lon[-2])/2)) # grid centers  \n",
    "\n",
    "    # # create mean temperature \n",
    "    # meanT=(tmax_xr+tmin_xr)/2    \n",
    "\n",
    "    # expand onto a grid\n",
    "    meanT_xr=meanT.expand_dims({'lon':lon,'lat':lat})\n",
    "\n",
    "    # now create a numpy array with dims (x,y,t) as in pyaez tutorial notebooks\n",
    "    meanT_np=meanT_xr.data\n",
    "\n",
    "    # last create dask array (chunked numpy array)\n",
    "    meanT_da=da.from_array(meanT_np,chunks=(int(nx/chunk_scale),int(ny/chunk_scale),nt))\n",
    "\n",
    "    return meanT_np, meanT_npda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data stored in 2 different ways\n",
    "# the function outputs:\n",
    "# numpy array with dims (nx,ny,nt)\n",
    "# dask array (numpy array broken into chunk) with dims (nx,ny,nt)\n",
    "\n",
    "meanT_np, meanT_npda = meanT_global_daily_dummy_data(nx,ny,nt,grids_per_degree,chunk_scale,tmax,tmin)\n",
    "\n",
    "# look at the size in GB\n",
    "meanT_npda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a single grid cell timeseries\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "plt.plot(meanT_np[0,0,:],marker='o',markersize=1,linewidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got daily mean temperature dummy data stored 2 different ways now:\n",
    "\n",
    "- in a numpy array, dims (nx,ny,nt)\n",
    "- in a dask array (numpy array broken into chunks), dims (nx,ny,nt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computations\n",
    "\n",
    "Here we use a 4 different approaches for computing the following at each gridbox \n",
    "- annual mean T\n",
    "- annual accumulated T\n",
    "- warmest day\n",
    "- coolest day\n",
    "\n",
    "We'll demonstrate how vectorization and parallelization affect computation speed. \n",
    "\n",
    "Note: I purposefully picked simple calculations and functions supported by all packages so none of the demos error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortran-style looping from numpy array\n",
    "\n",
    "this is super inefficient in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "\n",
    "# pre-allocate arrays to store results\n",
    "ann_meanT = np.empty((nx,ny)) \n",
    "ann_accT = np.empty((nx,ny))\n",
    "day_warmest = np.empty((nx,ny))\n",
    "day_coldest = np.empty((nx,ny)) \n",
    "\n",
    "# loop through each gridbox\n",
    "for ix in range(nx): \n",
    "    for iy in range(ny):\n",
    "        # single gridbox timeseries from numpy array \n",
    "        data_1D = meanT_np[ix,iy,:] \n",
    "        ann_meanT[ix,iy]=data_1D.mean()\n",
    "        ann_accT[ix,iy]=data_1D.sum()\n",
    "        day_warmest[ix,iy]=data_1D.argmax()+1\n",
    "        day_coldest[ix,iy]=data_1D.argmin()+1       \n",
    "\n",
    "tasktime = timer()-start\n",
    "tasktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on kerrie's windows desktop, 32GB RAM, grids_per_degree=8, (array size = 5.64GB): ~51.5 seconds\n",
    "\n",
    "on kerrie's windows laptop, 32GB RAM, grids_per_degree=24, (array size=51.75GB): ~268.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortran-style looping from numpy array sped up with numba\n",
    "\n",
    "numba speeds up loops by compiling the loops into machine code and executing the machine code\n",
    "\n",
    "notes: \n",
    "- numba only works with a subset of numpy functions. Something as simple as np.median can cause errors and more complicated numpy functions like polynomial fitting aren't supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything inside a function \n",
    "start=timer()\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def compute_stuff(nx,ny,data3D):\n",
    "    # pre-allocate arrays to store results\n",
    "    ann_meanT = np.empty((nx,ny)) \n",
    "    ann_accT = np.empty((nx,ny)) \n",
    "    day_warmest = np.empty((nx,ny)) \n",
    "    day_coldest = np.empty((nx,ny)) \n",
    "\n",
    "    for ix in range(nx): \n",
    "        for iy in range(ny):\n",
    "            # single gridbox timeseries from numpy array \n",
    "            data_1D = data3D[ix,iy,:] \n",
    "            ann_meanT[ix,iy]=data_1D.mean()\n",
    "            ann_accT[ix,iy]=data_1D.sum()\n",
    "            day_warmest[ix,iy]=data_1D.argmax()+1\n",
    "            day_coldest[ix,iy]=data_1D.argmin()+1 \n",
    "            \n",
    "    return ann_meanT, ann_accT, day_warmest, day_coldest       \n",
    "\n",
    "ann_meanT, ann_accT, day_warmest, day_coldest = compute_stuff(nx,ny,meanT_np)\n",
    "\n",
    "tasktime = timer()-start\n",
    "tasktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on kerrie's Windows desktop, 32GB RAM, grids_per_degree=8, (array size = 5.64GB): ~6.5 seconds\n",
    "\n",
    "on kerrie's windows laptop, 32GB RAM, grids_per_degree=24, (array size=51.75GB): ~34 seconds\n",
    "\n",
    "Numba appears to be lightning fast\n",
    "\n",
    "BUT for smaller data (e.g. data that fits in memory) this still won't be faster than simply using vectorized numpy functions, as we will see next\n",
    "\n",
    "for arrays bigger than memory, numba is way faster than numpy vectorization\n",
    "\n",
    "Also, problems arise with numba for more complicated computations or use of functions that aren't supported by numba. In these cases, which is often, you can get no speed ups or even slow downs vs the fortran-style looping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized Computation with numpy\n",
    "\n",
    "Numpy vectorization is always faster than loops- even loops sped up with numba. This is because numpy functions execute C scripts behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "\n",
    "# no need to pre-allocate\n",
    "# no loops, vectorize instead\n",
    "# indicate computation on the time dimension by passing axis=2\n",
    "\n",
    "ann_meanT=meanT_np.mean(axis=2)\n",
    "ann_accT=meanT_np.sum(axis=2)\n",
    "day_warmest=meanT_np.argmax(axis=2)+1\n",
    "day_coldest=meanT_np.argmin(axis=2)+1       \n",
    "\n",
    "tasktime = timer()-start\n",
    "tasktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on kerrie's Windows desktop, 32GB RAM, grids_per_degree=8, (array size = 5.64GB): ~5s\n",
    "\n",
    "on kerrie's windows laptop, 32GB RAM, grids_per_degree=24, (array size=51.75GB): ~301s wow, slower than fortan style looping! (this is only true for data bigger than memory)\n",
    "\n",
    "\n",
    "numpy vectorization results in slightly faster computation than fortran-style looping with numba for arrays that are smaller than memory\n",
    "\n",
    "it also reduces the amount of code to 4 simple lines\n",
    "\n",
    "additionally, numpy vectorization can apply to the entirety of the code, whereas numba loops can only speed up sections of simple code that is looped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Parallelized Computation with dask\n",
    "\n",
    "We can speed up the vectorized computations even further by dividing the data into chunks (chunked numpy array = dask array) and computing on multiple chunks at a time (parallelization) \n",
    "\n",
    "Let's look at a couple ways to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 1:\n",
    "\n",
    "let dask automatically parallelize (this uses a single machine scheduler by default)\n",
    "\n",
    "- use this if you're working with dask arrays\n",
    "- dask will automatically use however many cores and threads your computer has to execute simultaneous computations\n",
    "- this is super nice because not much modification of the code is necessary\n",
    "- but note that this methods doesn't scale to an HPC environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask\n",
    "# dask.config.set(scheduler='threads') # threads is the default\n",
    "\n",
    "start=timer()\n",
    "\n",
    "# here, we are essentially sending the data in chunks to sit in worker memory once so it's not loaded up for every individual computation\n",
    "# what we're actually doing is creating a \"future\" for each data chunk and then sending the futures to the workers to compute\n",
    "# in this way we can process more data than we have memory and get the results very quickly\n",
    "meanT_npda =meanT_npda.persist() \n",
    "# del meanT_np\n",
    "\n",
    "# these lines are lazy, meaning they don't actually compute anything\n",
    "# they simply store each task in a what's called a dask graph, for computation later\n",
    "ann_meanT=meanT_npda.mean(axis=2)\n",
    "ann_accT=meanT_npda.sum(axis=2)\n",
    "day_warmest=meanT_npda.argmax(axis=2)+1\n",
    "day_coldest=meanT_npda.argmin(axis=2)+1       \n",
    "\n",
    "# when we want the results, we have to call compute\n",
    "ann_meanT=ann_meanT.compute()\n",
    "ann_accT=ann_accT.compute()\n",
    "day_warmest=day_warmest.compute()\n",
    "day_coldest=day_coldest.compute()\n",
    "\n",
    "tasktime = timer()-start\n",
    "tasktime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa. Super fast and easy\n",
    "\n",
    "on kerrie's Windows desktop, 32GB RAM, grids_per_degree=8, (array size = 5.64GB): xx seconds\n",
    "\n",
    "on kerrie's windows laptop, 32GB RAM, grids_per_degree=24, (array size=51.75GB): ~11s WHAT?! so fast \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 2:\n",
    "\n",
    "connect to a distributed cluster vs using the single machine default\n",
    "\n",
    "first, we'll show code that doesn't run fast using this method and then we'll show how to fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all your computer's cores simulatenously, like a mini HPC cluster\n",
    "# click on the cluster info expand arrow to get information about workers/threads/memory\n",
    "# once you start a client in ipynb, you don't have to do it again unless you restart the kernel or if you client.close() \n",
    "# be careful not to start more than one client/cluster (you will get a warning if you do, just restart the kernel in that case and start over)\n",
    "\n",
    "# this way uses defaults and will be different per machine\n",
    "client=Client()#(processes=False)\n",
    "client\n",
    "\n",
    "# this way you can choose specific settings\n",
    "# i believe this scales to a single HPC node\n",
    "# to use multiple nodes, we'd have to use SlurmCluster instead of LocalCluster\n",
    "# from dask.distributed import LocalCluster\n",
    "# cluster=LocalCluster(n_workers=4, threads_per_worker=2, memory_limit='8GB')\n",
    "# client=Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up a client/cluster with dask.distributed will allow us to scale up to an HPC environment, but there are a couple of tricks....\n",
    "\n",
    "while using the automated method worked seamlessly, distributed doesn't like large items like meanT_npda in the task graph\n",
    "\n",
    "look what happens when we run the same exact code, except this time it's running on the distributed system\n",
    "\n",
    "(for smaller arrays, this will run but take a long time. for larger arrays, this will error, just keep moving through this notebook past the error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "\n",
    "# these lines are lazy, meaning they don't actually compute anything\n",
    "# they simply store each task in a what's called a dask graph, for computation later\n",
    "ann_meanT=meanT_npda.mean(axis=2)\n",
    "ann_accT=meanT_npda.sum(axis=2)\n",
    "day_warmest=meanT_npda.argmax(axis=2)+1\n",
    "day_coldest=meanT_npda.argmin(axis=2)+1       \n",
    "\n",
    "# when we want the results, we have to call compute\n",
    "ann_meanT=ann_meanT.compute()\n",
    "ann_accT=ann_accT.compute()\n",
    "day_warmest=day_warmest.compute()\n",
    "day_coldest=day_coldest.compute()\n",
    "\n",
    "tasktime = timer()-start\n",
    "print(tasktime)\n",
    "\n",
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we fix this? \n",
    "\n",
    "# the options below only work up to a certain size data. all bigger data errors. why? If automated dask can do it, we should be able to do it here if we adjust some settings\n",
    "\n",
    "there are a couple of options. The first option is to send the data chunks to the workers using persist, then execute the same exact code as above\n",
    "\n",
    "voila! we still get the warning and it's slighlty slower than the single machine dask, but scalable to HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =client.persist(meanT_npda)\n",
    "\n",
    "start=timer()\n",
    "\n",
    "# these lines are lazy, meaning they don't actually compute anything\n",
    "# they simply store each task in a what's called a dask graph, for computation later\n",
    "ann_meanT=data.mean(axis=2)\n",
    "ann_accT=data.sum(axis=2)\n",
    "day_warmest=data.argmax(axis=2)+1\n",
    "day_coldest=data.argmin(axis=2)+1       \n",
    "\n",
    "# when we want the results, we have to call compute\n",
    "ann_meanT=ann_meanT.compute()\n",
    "ann_accT=ann_accT.compute()\n",
    "day_warmest=day_warmest.compute()\n",
    "day_coldest=day_coldest.compute()\n",
    "\n",
    "tasktime = timer()-start\n",
    "print(tasktime)\n",
    "\n",
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's the other option?  to use scatter like the warning message suggests\n",
    "\n",
    "this method is faster than .persist(), but the problem with that is it requires us to make our code look very different\n",
    "- put our computations inside a function\n",
    "- scatter numpy data (not dask arrays) to the workers\n",
    "- submit our computations to the client\n",
    "- and the store the results in local variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_comps(data):\n",
    "    ann_meanT=data.mean(axis=2)\n",
    "    ann_accT=data.sum(axis=2)\n",
    "    day_warmest=data.argmax(axis=2)+1\n",
    "    day_coldest=data.argmin(axis=2)+1     \n",
    "    return ann_meanT, ann_accT, day_warmest, day_coldest\n",
    "\n",
    "start=timer()\n",
    "\n",
    "data_scattered = client.scatter(meanT_np)\n",
    "ann_meanT,ann_accT,day_warmest,day_coldest = client.submit(np_comps, data_scattered).result()\n",
    "\n",
    "# this also works instead of using .result()\n",
    "# futures=client.submit(np_comps, data_scattered)\n",
    "# ann_meanT,ann_accT,day_warmest,day_coldest=client.gather(futures)\n",
    "\n",
    "tasktime = timer()-start\n",
    "print(tasktime)\n",
    "\n",
    "del ann_meanT, ann_accT, day_warmest, day_coldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on kerrie's Windows desktop, grids_per_degree=8, (array size = 5.64GB):\n",
    "\n",
    "vectorized, parallelized computation is the fastest, requiring only xx seconds using dask's automated parallelization and xx-xx seconds using dask.distributed which is scalable to an HPC system \n",
    "\n",
    "\n",
    "- implementation of vectorized computation across the entire pyaez will provide the biggest speed gain\n",
    "- implementation of parallelized lazy computation on the heaviest comps will provide additional pyaez speed gains\n",
    "- implementation of additional parallelized lazy comps outside of the heaviest comps will slow pyaez down a little bit but will allow input of much larger datasets without running out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "\n",
    "We will only get dask speed gains for bigger data due to the overhead of the parallelization (see table below comparing times for different sized input data)\n",
    "\n",
    "grids_per_degree| array size | nchunks | fortran-style python | fortran-style python +numba | vectorized python | vectorized parallelized (dask)\n",
    "---|---|---|---|---|---|---\n",
    "2 | 360 MB | 16 | 3s | 1.5s | 0.3s | 1s   \n",
    "4 | 1.41 GB | 16 | 12.5s | 2.5s | 1.25s | 2s\n",
    "8 | 5.64 GB | 16 | 51.5s | 6.5s | 5s | 3.75s\n",
    "16 | 22.56 GB | 16 | 202.5s | 22.5s | 20s | 11s\n",
    "16 | 22.56 GB | 64 | n/a | n/a | n/a | 10s\n",
    "16 | 22.56 GB | 144 | n/a | n/a | n/a | 10s\n",
    "\n",
    "\n",
    "## Recommendation\n",
    "\n",
    "- eliminate use of loops and numba\n",
    "- implement vectorization throughout the entire code\n",
    "- implement dask for the heaviest computations\n",
    "- later, implement more dask to allow for memory improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('daskdemo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3677312941ddc49ef6e66d4b17159eca75aa407f5a46f93ed9168f894a002892"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
