{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import tarfile\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls and data paths\n",
    "\n",
    "data_dir=r'C://Users/kerrie/Documents/02_LocalData/tutorials/GHCNm/' # where to store data\n",
    "# data_dir='/c/Users/kerrie/Documents/02_LocalData/tutorials/GHCNm/' # where to store data\n",
    "data_url='https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm.tavg.latest.qcf.tar.gz'  # url of data file\n",
    "fn_data=data_url.split('/')[-1]  # filename\n",
    "\n",
    "meta_url='https://www.ncei.noaa.gov/pub/data/ghcn/v4/readme.txt'  # url of metadata file\n",
    "fn_meta=meta_url.split('/')[-1]  # filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files\n",
    "urlretrieve(meta_url,data_dir+fn_meta)\n",
    "urlretrieve(data_url,data_dir+fn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip/untar the data file\n",
    "with tarfile.open(data_dir+fn_data) as f:\n",
    "    f.extractall(path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the filenames of the unpacked data files\n",
    "datfile=glob.glob(data_dir+'*/*.dat')[0]\n",
    "invfile=glob.glob(data_dir+'*/*.inv')[0]\n",
    "\n",
    "datfile,invfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the readme.txt file that you've downloaded to see a description of how the data are arranged in the .dat and .inv data files.\n",
    "\n",
    "The readme tells us that the station information is given in the .inv file where each line of the file is 68 characters long and contains the\n",
    "station ID, lat, lon, elevation, and station name.\n",
    "\n",
    "The readme also tells us that the .dat file contains the monthly data values for each station. A single line of the .dat file is 115 characters \n",
    "long and contains the data for a single station (station ID, year, element, \n",
    "Jan data value, Jan data flag1, Jan data flag2, Jan data flag3, Feb data value, Feb data flag1, ... , Dec data flag3).  \n",
    "\n",
    "This format of this data as a conituous string on each line of the file means we will have to parse these strings so that we can work with the \n",
    "data as numerical values. You can imagine that it may be useful to parse these strings into large tables where each row is a station and each \n",
    "column is a different field (stationID, year, data value, etc). The most useful python package to use for this is called Pandas. Pandas will \n",
    "allow us to organize and easily query and manipulate tabular data in a data structure called a dataframe.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to parse our text strings into a dataframe\n",
    "# There are no column names in the data file so we need to manually type them here\n",
    "\n",
    "# Also, usually text file data has a separator like a space or comma between different data items which allows for easier file reading.\n",
    "# In this case there is no separator so we have to manually type where each data item begins and ends using the indexes in the readme file.\n",
    "\n",
    "# make a list of all the column names (from readme)\n",
    "colnames = ['ID','YEAR','ELEMENT',\n",
    "            'VALUE1','DMFLAG1','QCFLAG1','DSFLAG1',\n",
    "            'VALUE2','DMFLAG2','QCFLAG2','DSFLAG2',\n",
    "            'VALUE3','DMFLAG3','QCFLAG3','DSFLAG3',\n",
    "            'VALUE4','DMFLAG4','QCFLAG4','DSFLAG4',\n",
    "            'VALUE5','DMFLAG5','QCFLAG5','DSFLAG5',\n",
    "            'VALUE6','DMFLAG6','QCFLAG6','DSFLAG6',\n",
    "            'VALUE7','DMFLAG7','QCFLAG7','DSFLAG7',\n",
    "            'VALUE8','DMFLAG8','QCFLAG8','DSFLAG8',\n",
    "            'VALUE9','DMFLAG9','QCFLAG9','DSFLAG9',\n",
    "            'VALUE10','DMFLAG10','QCFLAG10','DSFLAG10',\n",
    "            'VALUE11','DMFLAG11','QCFLAG11','DSFLAG11',\n",
    "            'VALUE12','DMFLAG12','QCFLAG12','DSFLAG12']\n",
    "\n",
    "# column indexes of the start and end of each data item (from readme)\n",
    "# note the readme gives column numbers starting at 1, \n",
    "# but python indexing is zero-based and is exclusive of the end index\n",
    "splitcol=[0,11,15,19,24,25,26,27,32,33,34,35,40,41,42,43,48,49,50,51,56,57,58,59,64,65,66,67,72,73,74,75,80,81,82,83,88,89,90,91,96,97,98,99,104,105,106,107,112,113,114,115]\n",
    "\n",
    "with open(datfile) as f:\n",
    "    data=f.read()\n",
    "data\n",
    "\n",
    "# First we'll create an empty dataframe with all the appropriate columns (get the column names from the readme file)\n",
    "\n",
    "\n",
    "# do an example of read one line to 51 col df\n",
    "# do an example of read one line to 1 col of df then split\n",
    "\n",
    "\n",
    "\n",
    "    # print(data)\n",
    "    # exit\n",
    "\n",
    "\n",
    "    # for line in f:\n",
    "    #     data=[line[splitcol[i]:splitcol[i+1]] for i in range(len(splitcol)-1)]\n",
    "    #     df = pd.concat([df,pd.DataFrame([data],columns=colnames)],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # parse the string into the different data items (indexes from readme)\n",
    "    # data=[line[0:11],int(line[11:15]),line[15:19],\n",
    "    #     int(line[19:24]),line[24:25],line[25:26],line[26:27],\n",
    "    #     int(line[27:32]),line[32:33],line[33:34],line[34:35],\n",
    "    #     int(line[35:40]),line[40:41],line[41:42],line[42:43],\n",
    "    #     int(line[43:48]),line[48:49],line[49:50],line[50:51],\n",
    "    #     int(line[51:56]),line[56:57],line[57:58],line[58:59],\n",
    "    #     int(line[59:64]),line[64:65],line[65:66],line[66:67],\n",
    "    #     int(line[67:72]),line[72:73],line[73:74],line[74:75],\n",
    "    #     int(line[75:80]),line[80:81],line[81:82],line[82:83],\n",
    "    #     int(line[83:88]),line[88:89],line[89:90],line[90:91],\n",
    "    #     int(line[91:96]),line[96:97],line[97:98],line[98:99],\n",
    "    #     int(line[99:104]),line[104:105],line[105:106],line[106:107],\n",
    "    #     int(line[107:112]),line[112:113],line[113:114],line[114:115]]\n",
    "    # df=pd.DataFrame(data,columns=['line'])\n",
    "\n",
    "# df                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is advanced\n",
    "with open(datfile) as f:\n",
    "    # data is a generator object, which is like a lazy iterator\n",
    "    # we're describing how to split each line of the file up, but not doing it yet\n",
    "    # the generator object holds these instructions for later and doesn't use up memory\n",
    "    data=( [line[splitcol[i]:splitcol[i+1]] for i in range(len(splitcol)-1)] for line in f ) # generator object\n",
    "\n",
    "    # pandas can create a dataframe from a generator, which performs much faster and uses less memory \n",
    "    # than other techniques for converting the .dat file to a dataframe (such as append/concat line by line)\n",
    "    df=pd.DataFrame(data,columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('tutorials_simple')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "957efa23bb835907639de5eb4a56f03f6ae7a80dfdfd0cd2554d336fbf8b9b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
